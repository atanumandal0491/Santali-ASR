{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72097e10-f867-4e4b-9e03-e0a14c8a6746",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff18fa-76b2-4149-8402-2a4d44581af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa evaluate datasets jiwer gcsfs accelerate transformers==4.37.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901b1db-153c-417f-97b9-9b31becd2f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, torch, evaluate, os\n",
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "from transformers import Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801baee-79e2-4aaf-aa24-952c22ed8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initializing...')\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-large\", language=\"Bengali\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\", language=\"Bengali\", task=\"transcribe\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a12d44-a68a-4fcc-a534-c9a5363b8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd3cfdb-f5fa-43fe-aed4-6d9a2dc1daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9b4ea-a28d-4e71-9a38-a638d8d90226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio_array, sampling_rate = librosa.load(batch[\"path\"], sr=16000, mono=True)\n",
    "    batch[\"input_features\"] = feature_extractor(audio_array, sampling_rate=sampling_rate).input_features[0]\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e396844-13f7-4d2c-ab4c-a823ef846310",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('csv', data_files={'train': ['train.csv'], 'test': 'test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3215e-ddb3-47a0-bfc7-1a18f29f203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)\n",
    "ds = ds.map(prepare_dataset, num_proc=None)\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db85d04-2f4a-4608-bcb4-5960673058d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"ckpt/whisper-large-bn-snt\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=38,\n",
    "    max_steps=2000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=4,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=255,\n",
    "    # save_strategy=\"epoch\",\n",
    "    save_steps=20,\n",
    "    eval_steps=20,\n",
    "    logging_steps=1,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b6c3d-25b4-423a-aa22-8f3a67896d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"ckpt/whisper-large-bn-snt/checkpoint-2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a058899-3715-4ea0-a76f-7b415442d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    # train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79b048-eee3-4442-a780-e6ed50d84aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(eval_dataset=ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2764f-a44f-47b1-adb6-88e6d1565458",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.predict(test_dataset=ds[\"test\"]).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1f40b-ea5d-47ae-b376-14ab138c41bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = processor.batch_decode(evaluator.predict(test_dataset=ds[\"test\"], num_beams=5).predictions, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af71650-3c1f-41d2-8557-1552214f90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in transcription:\n",
    "    print(sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
