{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72097e10-f867-4e4b-9e03-e0a14c8a6746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar  5 08:28:18 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   50C    P0    75W / 300W |  42193MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fff18fa-76b2-4149-8402-2a4d44581af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /usr/local/lib/python3.9/dist-packages (0.10.1)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.9/dist-packages (0.4.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.4.0)\n",
      "Requirement already satisfied: jiwer in /usr/local/lib/python3.9/dist-packages (3.0.3)\n",
      "Requirement already satisfied: gcsfs in /usr/local/lib/python3.9/dist-packages (2024.2.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.9/dist-packages (0.27.2)\n",
      "Requirement already satisfied: transformers==4.37.2 in /usr/local/lib/python3.9/dist-packages (4.37.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (2.28.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (0.15.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (23.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (1.23.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.9/dist-packages (from transformers==4.37.2) (0.21.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.0.4)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.59.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.9.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.9/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2024.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.13)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.5.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.5.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.9/dist-packages (from jiwer) (3.6.1)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.9/dist-packages (from jiwer) (8.1.3)\n",
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.9/dist-packages (from gcsfs) (2.15.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.9/dist-packages (from gcsfs) (0.4.6)\n",
      "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.9/dist-packages (from gcsfs) (2.28.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (1.12.1+cu116)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (18.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth>=1.2->gcsfs) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth>=1.2->gcsfs) (4.7.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.37.2) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.37.2) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.37.2) (2.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage->gcsfs) (2.7.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage->gcsfs) (1.5.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage->gcsfs) (2.4.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage->gcsfs) (2.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.62.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.9/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (3.19.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.14.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install librosa evaluate datasets jiwer gcsfs accelerate transformers==4.37.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9901b1db-153c-417f-97b9-9b31becd2f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, torch, evaluate, os\n",
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "from transformers import Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d801baee-79e2-4aaf-aa24-952c22ed8ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "print('Initializing...')\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-large\", language=\"Bengali\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\", language=\"Bengali\", task=\"transcribe\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a12d44-a68a-4fcc-a534-c9a5363b8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd3cfdb-f5fa-43fe-aed4-6d9a2dc1daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e9b4ea-a28d-4e71-9a38-a638d8d90226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio_array, sampling_rate = librosa.load(batch[\"path\"], sr=16000, mono=True)\n",
    "    batch[\"input_features\"] = feature_extractor(audio_array, sampling_rate=sampling_rate).input_features[0]\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e396844-13f7-4d2c-ab4c-a823ef846310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d2b0043f2f7bafe2\n",
      "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-d2b0043f2f7bafe2/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee05dd465564421b87015f1dc1724d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset('csv', data_files={'train': ['train.csv'], 'test': 'test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe3215e-ddb3-47a0-bfc7-1a18f29f203b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['path', 'sentence'],\n",
      "        num_rows: 315\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['path', 'sentence'],\n",
      "        num_rows: 147\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4aeca8fbccf4f09b424c95637da9db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/315 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40672e15ff24ecf8d5deaeb3eb2f8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ds)\n",
    "ds = ds.map(prepare_dataset, num_proc=None)\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db85d04-2f4a-4608-bcb4-5960673058d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"ckpt/whisper-large-bn-snt\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=38,\n",
    "    max_steps=2000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=4,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=255,\n",
    "    # save_strategy=\"epoch\",\n",
    "    save_steps=20,\n",
    "    eval_steps=20,\n",
    "    logging_steps=1,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f36b6c3d-25b4-423a-aa22-8f3a67896d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7828a59ebf374814b2450a184563cb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"ckpt/whisper-large-bn-snt/checkpoint-2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a058899-3715-4ea0-a76f-7b415442d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    # train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef79b048-eee3-4442-a780-e6ed50d84aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.11536873877048492,\n",
       " 'eval_wer': 27.27272727272727,\n",
       " 'eval_runtime': 159.0504,\n",
       " 'eval_samples_per_second': 0.924,\n",
       " 'eval_steps_per_second': 0.233}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(eval_dataset=ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0d2764f-a44f-47b1-adb6-88e6d1565458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50258, 50260, 50359, ..., 50257, 50257, 50257],\n",
       "       [50258, 50260, 50359, ..., 50257, 50257, 50257],\n",
       "       [50258, 50260, 50359, ..., 50257, 50257, 50257],\n",
       "       ...,\n",
       "       [50258,    13, 50359, ..., 50257, 50257, 50257],\n",
       "       [50258, 50363, 50359, ..., 50257, 50257, 50257],\n",
       "       [50258,    13, 50359, ..., 50257, 50257, 50257]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.predict(test_dataset=ds[\"test\"]).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad1f40b-ea5d-47ae-b376-14ab138c41bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transcription = processor.batch_decode(evaluator.predict(test_dataset=ds[\"test\"], num_beams=5).predictions, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7af71650-3c1f-41d2-8557-1552214f90c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱥᱦᱟᱱᱰᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱭᱨᱟᱞᱮᱭᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱰᱨᱤᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱭᱟᱨᱤᱣᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱣᱮᱞᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱢᱤᱢᱭᱞᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱤᱧᱟᱜ ᱠᱷᱟᱛᱟ ᱨᱮ ᱢᱤᱫᱥᱟᱭ ᱯᱮᱜᱮᱞ ᱯᱩᱱ ᱴᱟᱠᱟ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱟᱭᱞᱮᱭᱜᱷᱼᱨᱚᱥᱮ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱭᱮᱞᱮ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱟᱡᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱱᱰᱚᱞᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱞᱟᱩᱰᱭᱚ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱩᱱᱜᱷ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱤᱢᱟᱱᱤ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱴᱲᱤᱭᱟ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱲᱮᱭ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱚᱞᱟᱱᱤ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱱᱜᱤᱦᱚᱱ ᱠᱟᱱᱟ᱾\n",
      ".ᱤᱧᱟᱜ ᱠᱷᱟᱛᱟ ᱨᱮ ᱤᱨᱟᱹᱞᱜᱮᱞ ᱴᱟᱠᱟ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱱᱭᱟᱥᱦᱟ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱞᱮᱪᱷᱩᱠᱣ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱠᱩᱭᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱟᱨᱞᱮᱭ ᱠᱟᱱᱟ᱾\n",
      "ᱟᱨ ᱟᱡ ᱠᱷᱚᱱ ᱟᱹᱲᱤ ᱜᱟᱛᱮ ᱞᱮᱭᱟᱜ ᱞᱮᱜᱟᱹᱧ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      ".ᱟᱡ ᱵᱟᱵᱟ ᱯᱩᱱᱜᱮᱞ ᱛᱩᱨᱩᱭ ᱴᱟᱠᱟ ᱮᱢᱟ ᱫᱮᱭᱟᱭ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱩᱥᱟᱣ ᱠᱟᱱᱟ᱾\n",
      ".ᱤᱧᱟᱜ ᱠᱷᱟᱛᱟ ᱨᱮ ᱯᱮ ᱜᱮᱞ ᱯᱩᱱ ᱴᱟᱠᱟ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      "ᱤᱧᱟᱜ ᱠᱷᱟᱛᱟ ᱨᱮ ᱢᱤᱫᱥᱟᱭ ᱯᱮᱜᱮᱞ ᱤᱨᱟᱹᱞ ᱴᱟᱠᱟ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱢᱟᱱᱤᱣᱮ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱯᱤ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱞᱤ ᱠᱟᱱᱟ᱾\n",
      "ᱣᱟᱹᱨᱥᱟᱜ ᱨᱮ ᱪᱮᱫᱤᱱᱮ ᱠᱟᱦᱤᱱᱟᱜ-ᱟᱹᱨᱥᱟ᱾\n",
      ".ᱵᱮᱝ ᱴᱷᱮᱱ ᱢᱚᱬᱮᱜᱮᱞ ᱤᱨᱟᱹᱞ ᱴᱟᱠᱟ ᱜᱮ ᱥᱟᱨᱮᱡ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱚᱪᱚ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱴᱷᱟ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱜᱤᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱢᱚᱛᱚᱨ ᱪᱷᱚᱞᱟ ᱫᱤᱱᱟᱜ ᱛᱮ ᱛᱮ ᱛᱟᱱᱟᱹᱧ ᱥᱮ ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱨᱢᱤᱱᱟ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱚᱰᱟ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱭᱞᱟᱦ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱭᱟᱠᱚ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱟᱱᱚᱴ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱣᱟᱱᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱤᱧᱟᱜ ᱠᱷᱟᱛᱟ ᱨᱮ ᱵᱮᱜᱮᱞ ᱢᱚᱬᱮ ᱴᱟᱠᱟ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱨᱶᱮᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱟᱨᱞᱤᱣᱮ ᱠᱟᱱᱟ᱾\n",
      "ᱥᱮᱢᱤᱱᱟᱜ ᱞᱤᱠᱟᱹᱭᱜᱮ ᱵᱚᱛᱩᱨᱵᱟᱱ ᱪᱟᱣᱟᱹᱞᱮᱱ ᱛᱟᱦᱟᱭ ᱞᱮᱜᱼᱟ ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱥᱤᱭᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱟᱭᱴᱤᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱱᱤᱥᱮᱱ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱟᱭᱞᱮᱥᱮ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱭᱞᱵᱭ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱞᱤᱱᱮ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱚᱱᱤᱭᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱱᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱟᱭᱟᱨ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱨᱩᱴᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱟᱰᱟᱨᱤᱣᱥ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱱᱤᱣᱮᱴ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱟᱭᱤᱱᱮᱴᱞᱟᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱨᱭᱥ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱭᱟᱨᱥᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱵᱮᱠ ᱴᱷᱮᱱ ᱢᱤᱫᱥᱟᱭ ᱮᱭᱟᱭᱜᱮᱞ ᱟᱨᱮ ᱴᱟᱠᱟ ᱜᱮ ᱥᱟᱨᱮᱡ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱟᱞᱤᱠ ᱠᱟᱱᱟ᱾\n",
      ".ᱤᱧᱟᱜ ᱠᱷᱟᱛᱟ ᱨᱮ ᱵᱟᱨ ᱴᱟᱠᱟ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      ".ᱠᱟᱛᱩ ᱨᱟᱹᱞᱟᱹ ᱫᱤᱥᱚᱢ ᱠᱚᱨᱮᱭᱤᱱ ᱠᱟᱱᱟᱜᱼᱟ ᱾\n",
      "ᱵᱮᱠ ᱠᱷᱮᱱ ᱤᱨᱟᱹᱞᱜᱮᱞ ᱢᱚᱬᱮ ᱴᱟᱠᱟ ᱜᱮ ᱥᱟᱨᱮᱡ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱭᱠᱚ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱭᱚᱱᱚ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱱᱜᱮᱥᱴᱮᱱ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱣᱮᱞ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱱᱚᱞ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱞᱴᱟᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱚᱣᱟᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱭᱟᱴᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱲᱢᱮᱴ ᱠᱟᱱᱟ᱾\n",
      ".ᱥᱮᱸᱫᱽᱨᱟᱜ ᱧᱩᱛᱩᱡᱚᱣ ᱠᱟᱱᱟᱜᱷᱟᱹᱭ ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱞᱶᱤᱱ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱠᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱚᱵᱤᱣᱮᱞᱤᱥ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱥᱤ ᱠᱟᱱᱟ᱾\n",
      "ᱤᱧ ᱴᱷᱮᱱ ᱢᱚᱬᱟᱹᱭᱜᱮᱞ ᱯᱮ ᱴᱟᱠᱟ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱨᱮᱢ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱭᱟᱞᱚᱦᱤ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱶᱤᱣᱱᱰᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱢᱚᱨᱤᱭᱟᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱣᱱᱜᱚᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱨᱭᱥᱴᱭᱤᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱞᱤᱡᱚ ᱠᱟᱱᱟ᱾\n",
      ".ᱟᱢ ᱴᱷᱮᱱ ᱫᱤᱱᱟᱹᱞᱟᱹᱣᱱᱢ ᱢᱮᱱᱟᱜᱼᱟᱹᱧᱟ ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱯᱦᱟᱨᱴᱷ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱦᱮᱢ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱰᱞᱟᱹᱭᱤᱱ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱭᱚᱨᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱤᱧᱟᱜ ᱵᱚᱦᱚᱜ ᱨᱮ ᱵᱤᱫᱥᱟᱭ ᱤᱭᱟᱹᱭᱜᱮᱞ ᱮᱭᱟᱝ ᱩᱵ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      "ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱴᱲᱤ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱞᱥᱮᱭ ᱠᱟᱱᱟ᱾\n",
      "ᱟᱡ ᱵᱟᱵᱟ ᱯᱮᱜᱮᱞ ᱤᱨᱟᱹᱞ ᱴᱟᱠᱟ ᱮᱢᱟ ᱫᱮᱭᱟᱭ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱭᱞᱟᱹᱭᱤᱱ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱭᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱟᱡ ᱵᱟᱵᱟ ᱯᱩᱱ ᱜᱮᱞ ᱴᱟᱠᱟ ᱮᱢᱟ ᱫᱮᱭᱟᱭ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱟᱭᱞᱮᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱟᱡ ᱵᱟᱵᱟ ᱯᱩᱱᱜᱮᱞ ᱢᱤᱫ ᱴᱟᱠᱟ ᱮᱢᱟ ᱫᱮᱭᱟᱭ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱟᱲᱩᱦᱚ ᱠᱟᱱᱟ᱾\n",
      "ᱴᱟᱜ ᱦᱩᱨᱩᱰᱟᱱ ᱦᱚᱲᱟᱹᱞᱚᱣ ᱞᱮᱭᱟᱜᱷ ᱞᱮᱜᱼᱟᱹᱧ ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱢᱮᱴᱨᱟ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱟᱭᱨᱤᱭᱟ ᱠᱟᱱᱟ᱾\n",
      "ᱩᱱᱤ ᱫᱚ ᱨᱩᱵᱩᱡᱟᱱ ᱛᱚᱰᱟᱜ ᱠᱮᱜᱟᱹᱧ ᱛᱚᱲᱟ ᱠᱮᱜᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱞᱮᱭᱜᱷ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱜᱩᱱᱰᱨᱟᱭ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱟᱭᱞᱚᱰᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱟᱡ ᱵᱟᱵᱟ ᱯᱩᱱᱜᱮᱞ ᱯᱩᱱ ᱴᱟᱠᱟ ᱮᱢᱟ ᱫᱮᱭᱟᱭ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱨᱤᱭᱟᱱ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱚᱰᱚᱭᱞᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱟᱡ ᱵᱟᱵᱟ ᱢᱤᱫᱥᱟᱭ ᱯᱩᱱᱜᱮᱞ ᱤᱨᱟᱹᱞ ᱴᱟᱠᱟ ᱮᱢᱟ ᱫᱮᱭᱟᱭ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱨᱥᱴᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱟᱞᱮᱥᱤ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱱᱤᱣᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱚᱨᱚᱱ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱣᱤᱭᱟᱱᱰᱨᱟ ᱠᱟᱱᱟ᱾\n",
      ".ᱤᱧ ᱴᱷᱮᱱ ᱢᱤᱫᱥᱟᱭ ᱵᱟᱨᱜᱮᱞ ᱢᱤᱫ ᱴᱟᱠᱟ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱣᱮᱭᱟᱱᱮᱨ ᱠᱟᱱᱟ᱾\n",
      "ᱵᱮᱠ ᱴᱷᱮᱱ ᱢᱤᱫᱥᱟᱭ ᱛᱩᱨᱩᱭᱜᱮᱞ ᱴᱟᱠᱟ ᱜᱮ ᱥᱟᱨᱮᱡ ᱠᱟᱱᱟ᱾\n",
      ".ᱵᱮᱠ ᱴᱷᱮᱱ ᱯᱮᱜᱮᱞ ᱯᱩᱢ ᱴᱟᱠᱟ ᱜᱮ ᱥᱟᱨᱮᱡ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱨᱤᱥᱚᱱ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱣᱮᱨᱟᱞᱮ ᱠᱟᱱᱟ᱾\n",
      "ᱤᱧᱟᱜ ᱵᱚᱦᱚᱜ ᱨᱮ ᱢᱤᱫᱥᱟᱭ ᱯᱮ ᱜᱮᱞ ᱢᱚᱴᱟᱝ ᱩᱵ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      "ᱨᱟᱭ ᱧᱩᱛᱩᱭ ᱫᱚ ᱯᱩᱭᱥᱚᱠᱚᱹᱭᱤᱫᱤᱭᱟᱜᱟ ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱨᱤᱥᱟ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱟᱭᱴᱷᱟᱱ ᱠᱟᱱᱟ᱾\n",
      "ᱤᱧ ᱴᱷᱮᱱ ᱢᱤᱫᱥᱟᱭ ᱢᱚᱬᱮᱜᱮᱞ ᱴᱟᱠᱟ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱭᱟᱱᱴᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱞᱥᱮᱭᱨᱚᱥᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱱᱰᱨᱭᱠ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱜᱟᱱ ᱠᱟᱱᱟ᱾\n",
      ".ᱵᱮᱜᱟᱹᱭᱟᱜ ᱞᱮᱭᱟᱜ ᱥᱟᱯᱷᱟᱹᱲᱟᱣ ᱠᱚᱨᱟᱣ ᱛᱟᱨᱟᱭ ᱯᱮ ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱥᱚᱱ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱮᱞᱤᱣᱮᱼᱢᱟᱨᱤᱣᱮ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱚᱨᱟᱭ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱟᱱᱰᱚᱠᱟᱨ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱟᱲᱵᱮᱠ ᱠᱟᱱᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱷᱟᱞᱮᱭᱟᱦ ᱠᱟᱱᱟ᱾\n",
      ".ᱵᱟᱨᱤ ᱯᱟᱵᱚᱥᱴᱟᱱ ᱨᱮ ᱡᱚᱢᱟᱹᱭᱟᱢ ᱠᱟᱱᱟ ᱾\n",
      ".ᱤᱧ ᱴᱷᱮᱱ ᱢᱤᱫᱥᱟᱭ ᱛᱩᱨᱩᱭᱜᱮᱞ ᱛᱩᱨᱩᱭ ᱴᱟᱠᱟ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      ".ᱤᱧ ᱴᱷᱮᱱ ᱢᱤᱫᱥᱟᱭ ᱵᱟᱨᱜᱮᱞ ᱵᱟᱨ ᱴᱟᱠᱟ ᱢᱮᱱᱟᱜᱼᱟ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱟᱲᱤᱢ ᱠᱟᱱᱟ᱾\n",
      "ᱢᱮᱱ ᱠᱷᱟᱱ ᱯᱟᱲᱦᱟᱹ ᱫᱚ ᱪᱟᱵᱟ ᱠᱮᱱᱟᱜᱼᱟᱭ ᱾\n",
      ".ᱩᱱᱤᱭᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱠᱤᱢ ᱠᱟᱱᱟ᱾\n"
     ]
    }
   ],
   "source": [
    "for sent in transcription:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240542dc-d864-4084-b88b-19a494337949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: ckpt/whisper-large-hi-snt/ (stored 0%)\n",
      "  adding: ckpt/whisper-large-hi-snt/vocab.json (deflated 69%)\n",
      "  adding: ckpt/whisper-large-hi-snt/added_tokens.json (deflated 80%)\n",
      "  adding: ckpt/whisper-large-hi-snt/tokenizer_config.json (deflated 96%)\n",
      "  adding: ckpt/whisper-large-hi-snt/runs/ (stored 0%)\n",
      "  adding: ckpt/whisper-large-hi-snt/runs/Mar07_02-23-45_n0d1rjx0k4/ (stored 0%)\n",
      "  adding: ckpt/whisper-large-hi-snt/runs/Mar07_02-23-45_n0d1rjx0k4/events.out.tfevents.1709778942.n0d1rjx0k4.32.0 (deflated 72%)\n",
      "  adding: ckpt/whisper-large-hi-snt/runs/Mar06_11-33-05_naculr041s/ (stored 0%)\n",
      "  adding: ckpt/whisper-large-hi-snt/runs/Mar06_11-33-05_naculr041s/events.out.tfevents.1709724789.naculr041s.69.0 (deflated 70%)\n",
      "  adding: ckpt/whisper-large-hi-snt/runs/Mar07_05-42-40_n4osr9ey8k/ (stored 0%)\n",
      "  adding: ckpt/whisper-large-hi-snt/runs/Mar07_05-42-40_n4osr9ey8k/events.out.tfevents.1709790406.n4osr9ey8k.33.0 (deflated 71%)\n",
      "  adding: ckpt/whisper-large-hi-snt/runs/Mar07_01-29-41_nl8q7cdy7l/ (stored 0%)\n",
      "  adding: ckpt/whisper-large-hi-snt/runs/Mar07_01-29-41_nl8q7cdy7l/events.out.tfevents.1709775467.nl8q7cdy7l.32.0 (deflated 62%)\n",
      "  adding: ckpt/whisper-large-hi-snt/runs/Mar06_16-35-18_n90r9n98i2/ (stored 0%)\n",
      "  adding: ckpt/whisper-large-hi-snt/runs/Mar06_16-35-18_n90r9n98i2/events.out.tfevents.1709743587.n90r9n98i2.59.0 (deflated 71%)\n",
      "  adding: ckpt/whisper-large-hi-snt/normalizer.json (deflated 81%)\n",
      "  adding: ckpt/whisper-large-hi-snt/special_tokens_map.json (deflated 80%)\n",
      "  adding: ckpt/whisper-large-hi-snt/preprocessor_config.json (deflated 42%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/ (stored 0%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/trainer_state.json (deflated 88%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/training_args.bin (deflated 49%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/optimizer.pt (deflated 8%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/model.safetensors.index.json (deflated 96%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/config.json (deflated 59%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/model-00002-of-00002.safetensors (deflated 7%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/generation_config.json (deflated 72%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/rng_state.pth (deflated 27%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/scheduler.pt (deflated 48%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/model-00001-of-00002.safetensors (deflated 7%)\n",
      "  adding: ckpt/whisper-large-hi-snt/checkpoint-2000/preprocessor_config.json (deflated 42%)\n",
      "  adding: ckpt/whisper-large-hi-snt/merges.txt (deflated 54%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r large-hi.zip ckpt/whisper-large-hi-snt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
